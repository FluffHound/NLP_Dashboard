{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><strong>Sistem Temu Kembali Informasi</strong><br />\n",
    "<strong><font color=\"blue\">Semester Gasal T.A. 2020/2021</font></strong><br />\n",
    "</center>\n",
    "\n",
    "<strong>Outline pertemuan minggu ke-4</strong><br />\n",
    "<li> Word Embedding </li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding\n",
    "\n",
    "<p> Representasi dari teks ke dalam dense matriks. Term yang memiliki makna serupa berada pada jarak yang berdekatan pada ruang vektor </p>\n",
    "<p> VSM merepresentasikan teks ke dalam sparse matriks </p>\n",
    "<p> Sparse matriks memiliki ukuran yang besar dan memiliki banyak nilai 0 </p>\n",
    "<p> Dense matriks ukurannya lebih kecil, dapat diinisialisasi, dan tidak memiliki nilai 0 </p>\n",
    "<h2><img alt=\"\" src=\"figures/3_word_embeddings.png\" style=\"height: 296px ; width: 602px\" /></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algoritma word embedding\n",
    "<ul>\n",
    "    <li> Skip-gram </li>\n",
    "    <li> CBoW (Continuous Bag of Words)</li>\n",
    "    <li> GloVe (Global Vector)</li>\n",
    "    <li> FastText </li>\n",
    "    <li> BERT (based on context) </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skip Gram dan CBoW\n",
    "<h2><img alt=\"\" src=\"figures/sg-cbow.png\"/></h2>\n",
    "\n",
    "<p> Dimana w(t) merupakan kata target dan w(t-n) - w(t+n) adalah konteks (kata yang berada disekitar kata target. n merupakan ukuran dari window size. Apabila n = 2 maka konteks didefinisikan sebagai 2 kata sebelum dan setelah kata target.</p>\n",
    "<p> Contoh: \"the big brown bear and the fox\"\n",
    "    <br>Apabila kata target adalah = \"brown\" dan n = 2 \n",
    "    <br>Maka: \n",
    "    <br>w(t) = \"brown\"\n",
    "    <br>w(t-2) = \"the\"\n",
    "    <br>w(t-1) = \"big\"\n",
    "    <br>w(t+1) = \"bear\"\n",
    "    <br>w(t+2) = \"and\"\n",
    "</p>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download 3 categoies from 20newgroup dataset\n",
    "# save it as binary\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['sci.med', 'talk.politics.misc',  'rec.autos']\n",
    "data = fetch_20newsgroups(subset='train', categories=categories,remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "dst_name = \"20newsgroup.pckl\"\n",
    "dst_path = os.path.join(\"data\", dst_name)\n",
    "with open(dst_path, 'wb') as fout:\n",
    "    pickle.dump(data, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism',\n",
      " 'comp.graphics',\n",
      " 'comp.os.ms-windows.misc',\n",
      " 'comp.sys.ibm.pc.hardware',\n",
      " 'comp.sys.mac.hardware',\n",
      " 'comp.windows.x',\n",
      " 'misc.forsale',\n",
      " 'rec.autos',\n",
      " 'rec.motorcycles',\n",
      " 'rec.sport.baseball',\n",
      " 'rec.sport.hockey',\n",
      " 'sci.crypt',\n",
      " 'sci.electronics',\n",
      " 'sci.med',\n",
      " 'sci.space',\n",
      " 'soc.religion.christian',\n",
      " 'talk.politics.guns',\n",
      " 'talk.politics.mideast',\n",
      " 'talk.politics.misc',\n",
      " 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "pprint(list(newsgroups_train.target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loada data pickle\n",
    "with open(dst_path, 'rb') as fin:\n",
    "    data = pickle.load(fin)\n",
    "\n",
    "data = [doc for doc in data.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOk boys and girls,\\n\\n\"What was the \\'Ogadan War\\'????\"\\n\\nThe Money Raised in Band-Aid covered How Much of\\nthe Cost of Which Soviet Client State to replace what\\ncatagory of weapon system lost in the aforementioned war?\\n\\nWhy was the Joke: \"We arm the World.\" Really Not that funny?\\n\\nGonzo Station is the designation for WHICH USN Op Area?\\nand the primary threat targets in the Area Were:.....\\n\\nciao\\ndrieux\\n\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "import re\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def preprocess(doc):\n",
    "    sents = sent_tokenize(doc)\n",
    "    sents_tok = list() # tokenisasi kalimat\n",
    "    for s in sents:\n",
    "        s = s.strip().lower() # case folding dan menghilangkan new line\n",
    "        s = s.replace(\"\\n\", \" \") # menggantikan \\n dengan spasi\n",
    "        s = re.sub(r'[^a-zA-Z0-9 ]', ' ', s) # menghapus simbol\n",
    "        s = re.sub(' +', ' ', s) # menghapus repetitive space\n",
    "        \n",
    "        sents_tok.append(s)\n",
    "    \n",
    "    return \" \".join(sents_tok)\n",
    "\n",
    "docs = list()\n",
    "for d in data:\n",
    "    docs.append(preprocess(d))\n",
    "#docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk membentuk word embedding digunakan library Gensim\n",
    "# Format inputan dari Gensim adalah list of words untuk setiap kalimat\n",
    "# Contoh pada dokumen:\n",
    "#       Tiger is the biggest cat alive. The tigers species can be divided into 5 groups.\n",
    "# Inputan yang dibutuhkan Gensim adalah:\n",
    "#       [\"tiger\", \"is\", \"the\", \"biggest\", \"cat\", \"alive\"], [\"the\", \"tigers\", \"species\", \n",
    "#        \"can\", \"be\", \"devided\", \"into\", \"5\", \"groups\"]\n",
    "#\n",
    "doc_gensim = [word_tokenize(d) for d in docs]\n",
    "#print(doc_gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# train skip-gram dengan library gensim\n",
    "#\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "d = 300\n",
    "model_sg = Word2Vec(doc_gensim, min_count=1, size=d, window=5, workers=-1)\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "model_path = os.path.join('model', 'model_sg.model')\n",
    "# model dari word embedding dapat disimpan dengan fungsi di bawah ini\n",
    "model_sg.save(model_path)\n",
    "\n",
    "# untuk menggunakan model yang telah disimpan sebelumnya dapat dilakukan\n",
    "# dengan memanfaatkan fungsi load, beberapa model membutuhkan waktu yang lama\n",
    "# karena memiliki ukuran yang besar\n",
    "model_sg_load = Word2Vec.load(model_path)\n",
    "\n",
    "print('DONE')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2 Vec menggunakan matriks dense\n",
    "\n",
    "<p>Penggunaan memori oleh Gensim</p>\n",
    "<p>Jumlah kata x size x 12 bytes <br>\n",
    "    Contoh: <br>\n",
    "    Jika terdapat 100.000 kata unik dengan menggunakan dimensi embedding 200 <br>\n",
    "    Maka memori yang dibutuhkan = 100.000 x 200 x 12 bytes = ~229MB\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.23108237e-03, -8.02676484e-04, -3.23985354e-04,  1.28359965e-03,\n",
       "       -1.23454630e-03,  2.43231596e-04, -1.51430408e-03,  1.23896624e-03,\n",
       "       -1.36310980e-03,  4.81080526e-04,  3.91767389e-04, -5.23407303e-04,\n",
       "       -1.00291264e-03, -7.79745460e-04,  1.54002185e-03, -9.50106012e-04,\n",
       "       -1.54890309e-04,  7.70264978e-06,  5.63529786e-04, -5.98794490e-04,\n",
       "        1.22962752e-03, -1.62316801e-03,  2.40724316e-04,  9.46418557e-04,\n",
       "        9.41080682e-04, -3.28972877e-04, -1.00694376e-03, -4.19931021e-04,\n",
       "        4.36858652e-04,  1.74907182e-04, -1.18424003e-04,  4.89391328e-04,\n",
       "        3.42271611e-04,  1.64676784e-03, -1.60131755e-03, -3.01632303e-04,\n",
       "       -5.26122807e-04, -1.00837671e-03,  4.58112685e-04, -6.43660096e-05,\n",
       "        9.44961794e-04,  7.14395079e-04,  5.05643548e-04,  1.10773498e-03,\n",
       "       -9.45286010e-04,  1.43273245e-03, -2.21142880e-04, -3.54002899e-04,\n",
       "       -1.17031636e-03,  9.68187058e-04,  1.33653020e-03, -1.07109104e-03,\n",
       "        1.50150037e-03, -9.78506287e-04,  6.56769727e-04, -1.53126125e-03,\n",
       "       -9.60030768e-04, -2.24245043e-04,  3.94609349e-04, -5.93716570e-04,\n",
       "       -1.48621586e-03, -5.61824243e-04, -1.29824807e-03, -1.56679982e-03,\n",
       "       -1.57436865e-04,  9.14033968e-04, -1.47156150e-03, -6.14209159e-04,\n",
       "       -1.51486450e-03, -9.91207198e-04, -1.46473956e-03,  1.31903926e-03,\n",
       "        6.66895881e-04, -1.46586238e-03,  1.64646294e-03,  1.39332406e-05,\n",
       "        1.00638682e-03, -1.39800482e-03,  6.58564793e-04,  1.42896629e-03,\n",
       "       -4.18401294e-04,  1.89959581e-04, -1.33210607e-03,  1.72824890e-04,\n",
       "       -1.23663759e-03, -1.64326886e-03,  5.41701098e-04,  1.21699041e-03,\n",
       "        1.15198153e-03,  1.02424028e-03,  2.78811785e-04,  3.60635488e-04,\n",
       "       -1.28481665e-03,  4.50516731e-04, -3.53231182e-04, -8.22156027e-04,\n",
       "        1.29354978e-03, -6.85645908e-04, -1.07725419e-03,  1.52207620e-03,\n",
       "       -1.51382328e-03, -1.50527782e-03, -1.07175112e-03, -6.39132049e-04,\n",
       "        8.35511251e-04,  1.29325187e-03, -9.46408196e-04, -9.38704005e-04,\n",
       "        7.26371305e-04, -1.30580657e-03,  5.94464771e-04, -1.54779141e-03,\n",
       "       -1.16218568e-03, -9.28716254e-05,  1.08609861e-03, -6.92550500e-04,\n",
       "       -5.83725690e-04,  1.47625234e-03,  1.28370908e-03, -4.44749225e-04,\n",
       "        1.48242142e-03,  5.59218053e-04, -9.43315317e-05,  9.19998914e-04,\n",
       "       -1.84561053e-04, -1.26885052e-03, -1.41029409e-03, -6.88420259e-04,\n",
       "        9.95892566e-04, -1.08966627e-03, -2.47204152e-04,  1.24586187e-03,\n",
       "        7.32842891e-04, -1.15406932e-03,  9.13610158e-04,  1.49180909e-04,\n",
       "        2.64068512e-04, -6.13535463e-04, -4.27108229e-04, -9.56450094e-05,\n",
       "        1.12462940e-03, -8.47322692e-04, -1.13994320e-04, -8.98906786e-04,\n",
       "        1.19546824e-03, -1.14864763e-03,  8.79824860e-04,  1.54217845e-03,\n",
       "       -1.60599872e-03,  1.27482426e-03, -2.15545457e-04,  1.39681844e-03,\n",
       "        8.94607510e-04,  4.03061684e-04,  4.23024205e-04,  9.77956573e-04,\n",
       "        5.60730521e-04,  1.08059146e-03, -2.53780396e-04,  3.60829814e-04,\n",
       "       -1.14891306e-03, -1.29413186e-03,  6.90592686e-04,  3.94903182e-04,\n",
       "       -2.32119724e-04, -8.83931818e-04, -1.25002675e-03,  5.41671528e-04,\n",
       "       -1.12652175e-04,  1.15060399e-03,  1.29692932e-03, -8.44292226e-05,\n",
       "       -7.14994312e-05, -4.21926554e-04,  1.38161762e-03,  5.06423588e-04,\n",
       "       -9.08513204e-04, -3.76075186e-04,  2.56791478e-04, -1.62182085e-03,\n",
       "        3.75973759e-04, -1.48311083e-03,  8.14279716e-04,  4.55727772e-04,\n",
       "       -1.65876967e-03,  1.30237511e-03, -2.47308577e-04,  1.55488460e-03,\n",
       "        1.47732586e-04, -8.95763224e-05,  1.67794176e-04, -1.15050259e-03,\n",
       "        1.20398658e-03, -1.05725008e-03,  1.35175046e-03, -7.05736980e-04,\n",
       "       -4.51889646e-05, -4.40365926e-04, -5.97837556e-04, -1.55941059e-03,\n",
       "       -3.63222585e-04, -8.69430485e-04,  4.02595091e-04,  1.89370199e-04,\n",
       "        5.82084002e-04,  1.44882535e-03, -3.90478817e-04, -1.10275199e-04,\n",
       "       -1.29994936e-03,  1.32750918e-03, -1.64184149e-03,  1.30540004e-03,\n",
       "        1.00062473e-03, -8.64117901e-05, -9.84491198e-04,  1.54877861e-03,\n",
       "       -8.15260748e-04, -1.87734215e-04, -7.01806275e-04,  1.90873339e-04,\n",
       "        1.41841266e-03, -6.34502678e-04, -4.34418005e-04, -1.63169252e-03,\n",
       "       -8.15053820e-04,  9.08104877e-04,  2.06373457e-04,  1.12810485e-04,\n",
       "        8.45256436e-04, -1.22735233e-04,  1.07724115e-03,  6.46836532e-04,\n",
       "       -9.13182565e-04, -8.25016527e-04, -1.45322527e-03,  8.72372009e-04,\n",
       "        1.63995614e-03,  4.57941962e-04,  1.22224865e-03, -1.47280539e-03,\n",
       "        1.59703393e-03,  4.07668820e-04, -8.04497278e-04,  7.42228003e-04,\n",
       "       -1.39405648e-03, -4.99556656e-04,  5.25317388e-04, -1.55516609e-03,\n",
       "       -1.53150910e-03, -4.75144625e-05, -2.81037763e-04, -1.62984850e-03,\n",
       "        1.32133707e-03, -9.05586581e-04, -4.60027746e-04, -3.23105603e-04,\n",
       "        1.18134893e-03,  1.26677332e-03, -6.06983842e-04,  1.58145471e-04,\n",
       "       -1.13235787e-03,  1.57960155e-03,  2.22156013e-05, -8.55116377e-05,\n",
       "       -1.09582406e-03, -1.04695628e-03, -3.45279113e-05,  6.59837155e-04,\n",
       "        6.10759656e-04,  3.11988377e-04,  1.13020418e-03, -3.14305100e-04,\n",
       "       -1.51532714e-03, -1.26942480e-03,  8.01211980e-04,  5.86610287e-04,\n",
       "        6.25622226e-04, -1.58625294e-03,  7.65589139e-05, -1.32410918e-04,\n",
       "        4.54616034e-04, -1.21853569e-04,  2.56523945e-05,  4.26348648e-04,\n",
       "       -1.46379229e-03, -1.63807929e-03, -8.37302185e-04, -1.52896205e-03,\n",
       "       -7.35828944e-04,  6.07642403e-04,  8.89539486e-04,  4.21139630e-05,\n",
       "        1.60881155e-03,  2.11673905e-05,  1.54750166e-03,  9.23157670e-04,\n",
       "       -1.26341044e-03, -1.35064445e-04, -1.62277499e-03,  1.46769371e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melihat vektor suatu kata\n",
    "model_sg.wv['car']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menghitung similarity vektor antar kata\n",
    "\n",
    "model_sg.wv.similarity('car', 'car')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('millions', 0.23960770666599274),\n",
       " ('tore', 0.23730003833770752),\n",
       " ('responces', 0.2234179526567459),\n",
       " ('diab', 0.22310039401054382),\n",
       " ('hp', 0.22308149933815002),\n",
       " ('indoctrinated', 0.2147151529788971),\n",
       " ('minimal', 0.20774942636489868),\n",
       " ('startrek', 0.20443326234817505),\n",
       " ('hyper', 0.19632530212402344),\n",
       " ('hitting', 0.19322627782821655)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Menampilkan top-N similar words\n",
    "\n",
    "model_sg.wv.similar_by_word('car', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gar', 0.23239296674728394),\n",
       " ('wnbc', 0.2048788070678711),\n",
       " ('gloom', 0.19768092036247253),\n",
       " ('floation', 0.19452424347400665),\n",
       " ('crank', 0.19183796644210815),\n",
       " ('honistly', 0.191462904214859),\n",
       " ('winegar', 0.1896638125181198),\n",
       " ('urologie', 0.1883377730846405),\n",
       " ('neurological', 0.18824419379234314),\n",
       " ('prostate', 0.18742118775844574)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mencari yang paling mirip dengan kata 'cars'\n",
    "model_sg.wv.most_similar('cars')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"figures/3_cosine.png\" style=\"height:400px; width:683px\" /></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error! kata \" entir \" tidak ada di training data\n"
     ]
    }
   ],
   "source": [
    "# error jika kata tidak ada di training data\n",
    "\n",
    "kata = 'entir'\n",
    "try:\n",
    "    print(model_sg.wv.most_similar(kata))\n",
    "except:\n",
    "    print('error! kata \"',kata,'\" tidak ada di training data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: ###\n",
    "<ul>\n",
    "    <li> Pada word2vec apabila suatu kata tidak terdapat dalam list vocabulary maka akan error </li>\n",
    "    <li> Kesalahan pengetikan (typo) bisa menimbulkan error </li>\n",
    "    <li> Untuk mangatasi hal ini dapat dilakukan dengan menggunakan algoritma lain, seperti FastText </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('intrigues', 4.4517652e-05), ('enduring', 4.4517652e-05), ('cardinal', 4.4517652e-05), ('shirer', 4.4517652e-05), ('chancellors', 4.4517652e-05), ('undermining', 4.4517652e-05), ('waning', 4.4517652e-05), ('strasser', 4.4517652e-05), ('schleicher', 4.4517652e-05), ('unite', 4.4517652e-05)]\n"
     ]
    }
   ],
   "source": [
    "# \"predict\" vector for new data without re-training from the beginning\n",
    "d1 = ['new','generation','nvidia','gpu','is','rtx']\n",
    "d2 = ['deep','learning','computation','mostly', 'on', 'gpu']\n",
    "d3 = ['the','rtx','gpu','capable','super','sampling','ssdl']\n",
    "D = [d1,d2,d3]\n",
    "model_sg.train(D, total_examples=len(D), epochs=model_sg.epochs)\n",
    "print(model_sg.predict_output_word('gpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"Latihan:\"><font color=\"blue\">Latihan 1:</font></h3>\n",
    "\n",
    "<ul> \n",
    "    <li> Bangunlah word embedding dengan data 3 kategori lainnya dari data 20newsGroup</li>\n",
    "    <li> Lakukan training menggunakan Skip-Gram dan CBoW </li>\n",
    "    <li> Apakah vektor yang dihasilkan oleh suatu kata sama? ketika menggunakan Skip-Gram dan CBoW </li>\n",
    "    <li> Apakah hasil top-n similar memperoleh vocabulary yang sama? </li>\n",
    "    <li> Apakah jumlah dimensi berpengaruh pada hasil top-n most similar? </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kerjakan latihan 1 pada cell berikut ini\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText (Facebook-2016)##\n",
    "<ul>\n",
    "    <li> Menggunakan Sub-words: app, ppl, ple - apple, sehingga dapat mengatasi permasalahan typo atau tidak adanya suatu kata dalam vocabularies </li>\n",
    "    <li> Paper: https://arxiv.org/abs/1607.04606  </li>\n",
    "    <li> Website: https://fasttext.cc/ </li>\n",
    "    <li> Source: https://github.com/facebookresearch/fastText </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Done'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "dim = 300 # Jumlah neurons = ukuran vektor = jumlah kolom\n",
    "model_ft = FastText(doc_gensim, size=dim, window=5, min_count=2, workers=-1)\n",
    "'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cart', 0.3586006462574005),\n",
       " ('carb', 0.34631019830703735),\n",
       " ('cars', 0.32502445578575134),\n",
       " ('carbs', 0.3238670527935028),\n",
       " ('carter', 0.3183533549308777),\n",
       " ('cards', 0.30618295073509216),\n",
       " ('cartel', 0.30090874433517456),\n",
       " ('carr', 0.2989318370819092),\n",
       " ('card', 0.2915874421596527),\n",
       " ('scar', 0.28857722878456116)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Menampilkan top-N similar words\n",
    "\n",
    "model_ft.wv.similar_by_word('car', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('carriers', 0.32694974541664124),\n",
       " ('car', 0.32502445578575134),\n",
       " ('stars', 0.32168301939964294),\n",
       " ('card', 0.3070753812789917),\n",
       " ('ears', 0.28709676861763),\n",
       " ('carr', 0.27693971991539),\n",
       " ('islanders', 0.27515748143196106),\n",
       " ('carb', 0.2651306092739105),\n",
       " ('years', 0.2617567479610443),\n",
       " ('gears', 0.26143354177474976)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mencari yang paling mirip dengan kata 'cars'\n",
    "model_ft.wv.most_similar('cars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32502446\n",
      "-0.008061564\n"
     ]
    }
   ],
   "source": [
    "# Melihat similarity antar kata\n",
    "\n",
    "print(model_ft.wv.similarity('cars', 'car'))\n",
    "print(model_sg.wv.similarity('cars', 'car'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('germans', 0.29016056656837463), ('humans', 0.2773742973804474), ('lemans', 0.24586813151836395), ('fans', 0.23251758515834808), ('loans', 0.22750471532344818), ('vans', 0.21468831598758698), ('orwell', 0.21389256417751312), ('thier', 0.20579759776592255), ('teens', 0.20407643914222717), ('evans', 0.20316636562347412)]\n"
     ]
    }
   ],
   "source": [
    "# Tidak error jika kata tidak ada di training data\n",
    "\n",
    "kata = 'beckmans'\n",
    "try:\n",
    "    print(model_ft.wv.most_similar(kata))\n",
    "except:\n",
    "    print('error! kata \"',kata,'\" tidak ada di training data')\n",
    "    \n",
    "\n",
    "# Tidak terjadi error saat kata tidak terdapat pada vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"Latihan:\"><font color=\"blue\">Latihan 2:</font></h3>\n",
    "\n",
    "<ul>\n",
    "\t<li>Apakah kelebihan dan kekurangan WE secara umum?</li>\n",
    "\t<li>Apakah kira-kira aplikasi yang dapat memanfaatkan WE?</li>\n",
    "\t<li>Apakah bisa dijadikan representasi dokumen? Bagaimana caranya?</li>\n",
    "\t<li>Bergantung pada apa sajakah performa model WE?</li>\n",
    "</ul>\n",
    "\n",
    "* Preprocessing apa yang sebaiknya dilakukan pada model Word Embedding?\n",
    "* Apakah Pos Tag bermanfaat disini? Jika iya bagaimana menggunakannya?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kerjakan latihan 2 pada cell berikut ini"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
